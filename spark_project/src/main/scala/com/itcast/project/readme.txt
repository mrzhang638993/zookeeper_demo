HDFS：不适合做批量的流式的存储的。因为存在大量的小文件的生成的。只适合用于批计算的操作的。HDFS不适合进行实时的数据的处理的。适合的是离线的批量的大量数据的分析操作
HBase适合实时插入数据,HDFS适合数据分析。hbase不适合一次性的读取大量的数据的。parquet的离线分析的话，吞吐量是很高的。hbase对于大量数据的处理性能等不适很高的。
Hbase可以做实时分析的，HDFS可以做离线的批量数据分析的。但存在问题:hbase的数据和hdfs的数据是不一致的，存在差异。

kudu的应用场景:工业物联网。
项目特点:1.数据量大;2.流式处理;3.数据需要进行存储;数据需要实时的处理得到想要的数据结果的。
1.方案一：spark streaming+HDFS，spark streaming进行流式操作的话，会生成很多的小文件的。
2.方案二: spark streaming+HDFS+小文件的合并，使用file-compact进行合并操作.缺点：文件的合并相当的复杂的。
文件正在被使用的话，文件的合并会存在问题的。不能讲结果覆盖到原来的位置的（已合并的文件不能覆盖正在使用的文件的）。
数据源源不断的来，需要源源不断的合并操作的，问题很麻烦的。不推荐使用的。
3.方案三:hbase+HDFS执行操作的。
4.kudu方案:在实时随机读写的性能上需要媲美HBASE的,在批量数据的处理上需要媲美HDFS的批处理的性能的。
#############################
OLAP以及OLTP的数据库的区别：
OLTP：需要做到快速的插入和实时的更新操作的。进行精确的查询操作的。OLTP不注重批量的查询和操作实现的。
OLAP:主要是基于批量加载数据的。使用OLAP同步OLAP
列式存储和行式存储：列式存储比较适合于OLAP系统的,便于进行分析操作的。行式存储比较适合于OLTP的数据库的。
OLTP不只有关系型的数据库的，还有mongodb的数据库的。
kudu是介于hbase和hdfs之间的。hdfs不太能够发挥硬件的性能的。

hbase对于数据读取和插入对应的是存在内存支持的，是比较适合大数据方面的数据的插入和读写的操作的。
kudu是不支持sql的。内部存储数据是关系表的。kudu大部分的情况下需要结合impala使用的。kudu和impala都是cloudera的产品的。
kudu不依赖hive和hadoop的。kudu是自成体系的。

kudu  master:管理的是总体的表的元数据的。管理表的访问路径的。数据存储在一个特殊的tablet中存储的。主要存储在内存的。master的tablet赋值因子是3个的。
会存在2个额外的副本的。
kudu的存储原理：kudu的代码对应的是c++书写的。
kudu的数据首先存储在的是内存中的，当内存中的数据满了的话。对应的数据会溢写到disk中的。

impala强依赖于hive的metastore的。hive依赖于hdfs的。hive的版本是cdh的版本的。
安装cdh版本的hadoop以及cdh版本的hive等的版本的数据的。所有的版本对应的需要安装的是cdh版本的操作的。

所有的分布式服务的，在一次io的时间内是同步的。
主机名称称之为FQDN，cdh01.itcast.cn  称之为主机名称的。其中cdh01称之为主机名称的简写操作的。







